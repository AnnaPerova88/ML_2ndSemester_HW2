# ML_2ndSemester_HW2


Реализация логистической регрессии с нуля
Этот код представляет собой полную реализацию алгоритма логистической регрессии с использованием градиентного спуска для бинарной классификации.

Основные компоненты


## 1. Вспомогательные функции
Сигмоида: Преобразует линейную комбинацию в вероятность (0-1)

Log Loss: Вычисляет функцию потерь и градиент для оптимизации

Оптимизация: Реализует градиентный спуск для обновления весов

Предсказание: Классифицирует примеры с пороговым значением 0.5

## 2. Генерация данных
Создаются синтетические данные с двумя признаками

Добавляется нормальный шум для реалистичности

Целевая переменная генерируется с использованием сигмоидной функции

## 3. Обучение модели
Инициализация начальных весов нулями

1000 итераций градиентного спуска с learning rate 0.1

Визуализация сходимости функции потерь

## 4. Оценка качества
Расчет точности предсказаний

Демонстрация итоговых весов и смещения

## Результаты

График сходимости показывает стабильное уменьшение потерь
Итоговая точность модели: 97%

## Найденные параметры:

### Веса: [0.48, -0.46]

### Смещение: 0.02

## Использование
Код можно адаптировать для:

* Работы с реальными данными (заменив блок генерации)
* Экспериментов с гиперпараметрами (learning rate, iterations)
* Решения задач бинарной классификации
* Обучения принципам работы градиентного спуска

Требования: NumPy, Matplotlib
